#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Builds a high-quality, diverse Supervised Fine-Tuning (SFT) dataset for LoRA
training from a unified e-commerce product corpus.

This script transforms a RAG-focused JSONL file (where each line is a product
with its metadata) into a conversational, instruction-based SFT dataset in the
chat format: {"messages": [{"role": "user", ...}, {"role": "assistant", ...}]}.

The goal is to create a dataset that teaches the model various skills:
- Simple fact retrieval (price, brand, specs).
- Information synthesis and summarization.
- Consistent persona and role-playing (e.g., a helpful assistant).
- Handling multi-turn conversational context.
- Understanding linguistic variety through template-based augmentation.

Just run: python build_sft_dataset.py
"""
import json
import random
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# ----------------------------
# Configuration
# ----------------------------
# Input: The JSONL file generated by your RAG corpus script.
CORPUS_JSONL_PATH = Path("out/daraz_products_corpus.jsonl")

# Output: The final training dataset for your LoRA script.
SFT_TRAIN_JSONL_PATH = Path("out/ecom_sft_advanced.train.jsonl")

# Optional: Create a smaller validation set to monitor training progress.
SFT_VAL_JSONL_PATH = Path("out/ecom_sft_advanced.val.jsonl")
VAL_SET_SIZE = 200  # Number of products to use for the validation set

# Controls how many conversational examples are generated per product.
# A higher number increases dataset size and variety but takes longer.
EXAMPLES_PER_PRODUCT = 5

# System prompt to define the assistant's persona.
SYSTEM_PROMPT = (
    "You are a friendly, knowledgeable, and enthusiastic e-commerce assistant "
    "for 'Daraz'. Your primary goal is to provide accurate information and help "
    "customers make informed decisions about products. Be clear and helpful."
)

# -------------------------------------------------------------
# Data Augmentation Templates for Linguistic Variety
# -------------------------------------------------------------
# By using random templates, we teach the model to understand intent,
# not just specific keywords.

T_PRICE = [
    "How much does the {title} cost?",
    "What is the price of the {title}?",
    "Can you tell me the price for {title}?",
    "I'm interested in the {title}. What's the price tag?",
    "Show me the price for the product '{title}'.",
]

T_BRAND = [
    "Who makes the {title}?",
    "What is the brand of the {title}?",
    "Can you tell me the manufacturer of the {title}?",
    "I'd like to know the brand for '{title}'.",
]

T_RATING = [
    "What's the customer rating for the {title}?",
    "How do customers rate the {title}?",
    "Tell me about the reviews for the {title}.",
    "What is the average rating of '{title}'?",
]

T_SUMMARY = [
    "Can you give me a quick summary of the {title}?",
    "Summarize the main features of the {title}.",
    "Tell me the key details about the {title}.",
    "Provide an overview of the product '{title}'.",
    "I need a short description of the {title}.",
]

T_DELIVERY = [
    "What are the delivery options for the {title}?",
    "How can I get the {title} delivered?",
    "Tell me about the shipping for '{title}'.",
]

T_WARRANTY = [
    "Is there a warranty for the {title}?",
    "What is the return and warranty policy for the {title}?",
    "Tell me about the warranty details for '{title}'.",
]


class SFT_Generator:
    """
    A class to generate a diverse set of SFT examples from a product record.
    Each method is a "skill" we want to teach the model.
    """

    def __init__(self, product_record: Dict[str, Any]):
        self.meta = product_record.get("metadata", {})
        self.product_id = self.meta.get("id", "N/A")
        self.title = self.meta.get("title", "this product")

        # A list of all generator methods available.
        self.generators = [
            self.gen_price_and_rating,
            self.gen_summary,
            self.gen_brand_and_category,
            self.gen_delivery_info,
            self.gen_warranty_info,
            self.gen_multi_turn_dialogue,
        ]

    def _create_chat(self, user_content: str, assistant_content: str, use_system: bool = False) -> Dict[str, Any]:
        """Helper to format a conversation into the required JSON structure."""
        messages = []
        if use_system and SYSTEM_PROMPT:
            messages.append({"role": "system", "content": SYSTEM_PROMPT})
        messages.append({"role": "user", "content": user_content})
        messages.append({"role": "assistant", "content": assistant_content})
        return {"messages": messages}

    # --- Individual Skill Generators ---

    def gen_price_and_rating(self) -> Optional[Dict[str, Any]]:
        price = self.meta.get("price_display")
        rating_avg = self.meta.get("rating_average")
        rating_count = self.meta.get("rating_count")

        if not price or rating_avg is None:
            return None

        question = random.choice(T_PRICE).format(title=self.title)
        answer = f"The '{self.title}' is priced at {price}. "

        if rating_avg is not None:
            answer += f"It has a customer rating of {rating_avg} out of 5"
            if rating_count:
                answer += f" from {rating_count} reviews."
            else:
                answer += "."
        
        return self._create_chat(question, answer, use_system=True)

    def gen_brand_and_category(self) -> Optional[Dict[str, Any]]:
        brand = self.meta.get("brand")
        category = self.meta.get("category")

        if not brand or not category:
            return None

        question = random.choice(T_BRAND).format(title=self.title)
        answer = f"The '{self.title}' is from the brand **{brand}** and belongs to the **{category}** category."
        return self._create_chat(question, answer)

    def gen_summary(self) -> Optional[Dict[str, Any]]:
        description = self.meta.get("description")
        if not description:
            return None
        
        # We use the existing description as the assistant's answer for summarization.
        question = random.choice(T_SUMMARY).format(title=self.title)
        answer = f"Of course! Here is a summary for the '{self.title}':\n\n{description}"
        return self._create_chat(question, answer, use_system=True)

    def gen_delivery_info(self) -> Optional[Dict[str, Any]]:
        delivery_options = self.meta.get("delivery_options")
        if not delivery_options or not isinstance(delivery_options, list):
            return None

        question = random.choice(T_DELIVERY).format(title=self.title)
        answer_parts = [f"Here are the delivery options for the '{self.title}':"]
        for opt in delivery_options:
            if isinstance(opt, dict):
                bits = []
                if opt.get("title"): bits.append(opt["title"])
                if opt.get("time"): bits.append(f"({opt['time']})")
                if opt.get("fee"): bits.append(f"- Fee: {opt['fee']}")
                if bits: answer_parts.append(f"- {' '.join(bits)}")
        
        if len(answer_parts) <= 1:
            return None

        return self._create_chat(question, "\n".join(answer_parts))

    def gen_warranty_info(self) -> Optional[Dict[str, Any]]:
        warranty = self.meta.get("return_and_warranty")
        if not warranty or not isinstance(warranty, list):
            return None
            
        question = random.choice(T_WARRANTY).format(title=self.title)
        answer_parts = [f"Certainly! Here is the return and warranty information for the '{self.title}':"]
        answer_parts.extend([f"- {item}" for item in warranty if item])

        if len(answer_parts) <= 1:
            return None
            
        return self._create_chat(question, "\n".join(answer_parts), use_system=True)

    def gen_multi_turn_dialogue(self) -> Optional[Dict[str, Any]]:
        # This creates a more complex, two-turn conversation.
        brand = self.meta.get("brand")
        price = self.meta.get("price_display")
        rating_avg = self.meta.get("rating_average")

        if not brand or not price:
            return None

        # Turn 1
        q1 = f"Hi, I'm looking at the '{self.title}'. Who makes it?"
        a1 = f"Hello! The '{self.title}' is made by **{brand}**. Is there anything else I can help you with?"

        # Turn 2
        q2 = "Yes, what's the price? And how do customers find it?"
        a2 = f"The current price is {price}. "
        if rating_avg is not None:
            a2 += f"It's very well-regarded by customers, with an average rating of {rating_avg}/5."
        else:
            a2 += "I don't have specific rating information available at the moment."
        
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": q1},
            {"role": "assistant", "content": a1},
            {"role": "user", "content": q2},
            {"role": "assistant", "content": a2},
        ]
        return {"messages": messages}


def main():
    """Main function to generate the SFT dataset."""
    if not CORPUS_JSONL_PATH.exists():
        raise FileNotFoundError(f"Corpus file not found! Please run the RAG script first: {CORPUS_JSONL_PATH}")

    print("Bismillah! Starting SFT dataset generation.")
    print(f"Reading RAG corpus from: {CORPUS_JSONL_PATH}")

    all_products = []
    with CORPUS_JSONL_PATH.open("r", encoding="utf-8") as f:
        for line in f:
            all_products.append(json.loads(line))
    
    print(f"Loaded {len(all_products):,} products from the corpus.")
    random.shuffle(all_products)

    # Split into training and validation sets
    if len(all_products) <= VAL_SET_SIZE:
        raise ValueError("Not enough products to create a validation set. Please reduce VAL_SET_SIZE.")
    val_products = all_products[:VAL_SET_SIZE]
    train_products = all_products[VAL_SET_SIZE:]
    
    print(f"Allocating {len(train_products):,} products for training and {len(val_products):,} for validation.")

    # --- TRAINING SET GENERATION (This part was already correct) ---
    sft_record_count = 0
    with SFT_TRAIN_JSONL_PATH.open("w", encoding="utf-8") as f_train:
        for product in train_products:
            generator = SFT_Generator(product)
            generated_examples = 0
            available_gens = generator.generators.copy()
            random.shuffle(available_gens)

            for gen_func in available_gens:
                if generated_examples >= EXAMPLES_PER_PRODUCT:
                    break
                example = gen_func()
                if example:
                    f_train.write(json.dumps(example, ensure_ascii=False) + "\n")
                    generated_examples += 1
                    sft_record_count += 1

    print(f"Successfully wrote {sft_record_count:,} training examples to: {SFT_TRAIN_JSONL_PATH}")

    # =================================================================
    # --- VALIDATION SET GENERATION (Corrected and made resilient) ---
    # =================================================================
    val_record_count = 0
    with SFT_VAL_JSONL_PATH.open("w", encoding="utf-8") as f_val:
        for product in val_products:
            generator = SFT_Generator(product)
            example = None
            
            # --- THE FIX: Try multiple generator types until one succeeds ---
            # We create a list of preferred, simple generator functions to try in order.
            # This ensures we get a validation example if ANY of this data is present.
            preferred_gens = [
                generator.gen_price_and_rating,
                generator.gen_summary,
                generator.gen_brand_and_category,
                generator.gen_delivery_info,
            ]
            
            for gen_func in preferred_gens:
                example = gen_func()
                if example:
                    # As soon as we get one valid example, we stop trying for this product.
                    break
            
            if example:
                f_val.write(json.dumps(example, ensure_ascii=False) + "\n")
                val_record_count += 1
    
    print(f"Successfully wrote {val_record_count:,} validation examples to: {SFT_VAL_JSONL_PATH}")
    print("\nAlhamdulillah! Dataset generation complete. You are ready to begin training.")


if __name__ == "__main__":
    main()